# ğŸ”„ Unified Data Pipeline

> **CRITICAL**: This document describes the SINGLE SOURCE OF TRUTH for data loading.
> ALL components (Streamlit, React, API, Notebooks) MUST use this pipeline.

---

## ğŸ¯ The Problem We're Solving

Multiple implementations existed:
- `src/services/data_service.py` - Streamlit's data loading
- `src/data_manager/manager.py` - API's DataManager
- `src/data_manager/intake_bridge.py` - Catalog bridge
- Direct API calls scattered in React

This caused:
- Duplicated code
- Inconsistent behavior
- Hard-to-maintain codebase
- Confusion about which to use

---

## âœ… The Solution: Unified Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACES                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Streamlit   â”‚   â”‚    React     â”‚   â”‚       Notebooks          â”‚ â”‚
â”‚  â”‚  (sidebar)   â”‚   â”‚ (DataExplorer)â”‚  â”‚   (j2_utils imports)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                       â”‚
          â–¼                  â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       UNIFIED API LAYER                              â”‚
â”‚                                                                      â”‚
â”‚  FastAPI Router: /api/v1/data/*                                     â”‚
â”‚  - POST /data/load     (load data by catalog ID)                    â”‚
â”‚  - GET  /data/catalog  (list all datasets)                          â”‚
â”‚  - POST /data/download (download from remote API)                   â”‚
â”‚  - GET  /data/preview  (preview without full load)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DATA SERVICE LAYER                               â”‚
â”‚                                                                      â”‚
â”‚  src/services/data_service.py                                       â”‚
â”‚  - Agnostic to data source                                          â”‚
â”‚  - Routes based on catalog.yaml config                              â”‚
â”‚  - NO hardcoded paths or API keys                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CATALOG & ROUTING LAYER                           â”‚
â”‚                                                                      â”‚
â”‚  catalog.yaml (source of truth for all datasets)                    â”‚
â”‚  â”‚                                                                   â”‚
â”‚  â”œâ”€â”€ cmems_sealevel  â†’ CopernicusCatalog client                     â”‚
â”‚  â”œâ”€â”€ cmems_sst       â†’ CopernicusCatalog client                     â”‚
â”‚  â”œâ”€â”€ era5_reanalysis â†’ ERA5Client                                   â”‚
â”‚  â”œâ”€â”€ noaa_tides      â†’ NOAAClient                                   â”‚
â”‚  â”œâ”€â”€ local_slcci     â†’ Local NetCDF loader                          â”‚
â”‚  â””â”€â”€ demo_*          â†’ Mock data generator                          â”‚
â”‚                                                                      â”‚
â”‚  src/data_manager/intake_bridge.py - IntakeCatalogBridge            â”‚
â”‚  - Reads catalog.yaml                                               â”‚
â”‚  - Instantiates appropriate client                                  â”‚
â”‚  - Returns xarray Dataset                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CMEMS Client    â”‚ â”‚   ERA5 Client    â”‚ â”‚   Local Loader   â”‚
â”‚                  â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ CopernicusCatalogâ”‚ â”‚   ERA5Client     â”‚ â”‚  xr.open_dataset â”‚
â”‚ (736 lines!)     â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚                  â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ Uses env vars:   â”‚ â”‚ Uses env vars:   â”‚ â”‚ Uses paths from  â”‚
â”‚ CMEMS_USERNAME   â”‚ â”‚ CDS_API_KEY      â”‚ â”‚ config/datasets  â”‚
â”‚ CMEMS_PASSWORD   â”‚ â”‚                  â”‚ â”‚ .yaml            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Key Files

| File | Purpose | Status |
|------|---------|--------|
| `catalog.yaml` | Master dataset catalog | âœ… EXISTS |
| `config/datasets.yaml` | Secondary config | âœ… EXISTS |
| `src/data_manager/intake_bridge.py` | Catalog bridge | âœ… EXISTS |
| `src/data_manager/catalog.py` | CMEMS client (736 lines) | âœ… EXISTS |
| `src/surge_shazam/data/era5_client.py` | ERA5 client | âœ… EXISTS |
| `src/surge_shazam/data/cmems_client.py` | CMEMS simple client | âœ… EXISTS |
| `src/services/data_service.py` | Unified service | ğŸ”„ NEEDS UPDATE |
| `api/routers/data_router.py` | API endpoints | âœ… EXISTS |

---

## ğŸ”§ Environment Variables (REQUIRED)

```bash
# CMEMS (Copernicus Marine)
export CMEMS_USERNAME="your-username"
export CMEMS_PASSWORD="your-password"

# ERA5 (CDS)
export CDS_API_KEY="your-api-key"

# Optional: Override cache directory
export DATA_CACHE_DIR="/path/to/cache"
```

These are already configured in Alemusica's environment!

---

## ğŸš€ How to Load Data (The RIGHT Way)

### From Streamlit

```python
from src.services import DataService, GateService

# 1. Get gate (spatial bounds)
gs = GateService()
gate = gs.get_gate("fram_strait")

# 2. Build request from catalog
ds = DataService()
request = ds.build_request(
    gate=gate,
    dataset_id="cmems_sealevel",  # From catalog.yaml!
    time_range=TimeRange(start="2024-01-01", end="2024-12-31")
)

# 3. Load - DataService routes to correct client automatically
data = ds.load(request)
```

### From React

```typescript
// Call the API, NOT direct API calls to CMEMS/ERA5!
const response = await fetch(`${API_BASE}/data/load`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    dataset_id: 'cmems_sealevel',  // From catalog!
    bbox: { lat_min: 78, lat_max: 80, lon_min: -20, lon_max: 10 },
    time_range: { start: '2024-01-01', end: '2024-12-31' }
  })
});
```

### From Notebooks

```python
# Use the intake catalog directly
import intake
cat = intake.open_catalog('catalog.yaml')

# List available
print(cat.list())

# Load with metadata
ds = cat.cmems_sealevel.read()
```

---

## âŒ FORBIDDEN Patterns

```python
# âŒ NEVER DO THIS - Hardcoded paths
data_dir = "/Users/nicolocaron/Desktop/ARCFRESH/J2"

# âŒ NEVER DO THIS - Direct API calls bypassing catalog
import copernicusmarine
ds = copernicusmarine.open_dataset(...)

# âŒ NEVER DO THIS - Hardcoded credentials
username = "myuser"
password = "mypass"

# âŒ NEVER DO THIS - Duplicate client implementations
class MyOwnCMEMSClient:
    ...
```

---

## ğŸ“Š Adding a New Dataset

1. **Add to `catalog.yaml`**:
```yaml
sources:
  my_new_dataset:
    driver: intake_xarray.netcdf.NetCDFSource
    description: "My new data source"
    metadata:
      provider: MyProvider
      variables: [var1, var2]
      latency_badge: "ğŸŸ¡"
      client: "src.my_module.MyClient"
      status: available
```

2. **Create client if needed** (in `src/surge_shazam/data/`):
```python
class MyClient:
    def load(self, bbox, time_range, variables):
        # Implementation
        return xr.Dataset(...)
```

3. **Register in `intake_bridge.py`** if special handling needed.

4. **TEST IT**:
```python
from src.data_manager.intake_bridge import IntakeCatalogBridge
cat = IntakeCatalogBridge()
ds = cat.load("my_new_dataset", bbox=..., time_range=...)
```

---

## ğŸ”„ Migration Path

Current state â†’ Unified pipeline:

1. âœ… `catalog.yaml` exists with all datasets
2. âœ… `IntakeCatalogBridge` can route to clients
3. ğŸ”„ `DataService` needs to use `IntakeCatalogBridge` instead of custom routing
4. ğŸ”„ Streamlit sidebar needs to call DataService correctly
5. âœ… React already calls API endpoints

---

## ğŸ“ Related Issues

- #16 - Architecture Agent (coordination)
- Need: Data pipeline unification issue

---

*Last updated: 29 Dec 2025 - Session 2*
