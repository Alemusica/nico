"""
üî¨ PCMCI Causal Discovery Engine
================================

Real implementation of PCMCI (Peter-Clark Momentary Conditional Independence)
for time-lagged causal discovery using Tigramite.

Features:
- Multiple conditional independence tests (ParCorr, CMI, GPDC)
- Cross-validation of causal links
- Confidence scoring based on p-values
- Support for mixed variable types
- Climate-aware lag selection

Requirements:
    pip install tigramite

Usage:
    from src.pattern_engine.causal.pcmci_engine import PCMCIEngine
    
    engine = PCMCIEngine(max_lag=30, alpha=0.05)
    result = await engine.discover(df, target="flood_severity")
    
    for link in result.significant_links:
        print(f"{link.source} ‚Üí {link.target} (lag={link.lag}, score={link.score:.3f})")
"""

import numpy as np
import pandas as pd
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Any, Tuple
from datetime import datetime
import logging
import warnings

logger = logging.getLogger(__name__)

# Check for tigramite
try:
    import tigramite
    from tigramite import data_processing as pp
    from tigramite.pcmci import PCMCI
    from tigramite.independence_tests.parcorr import ParCorr
    HAS_TIGRAMITE = True
    
    # Optional tests
    try:
        from tigramite.independence_tests.cmiknn import CMIknn
        HAS_CMI = True
    except ImportError:
        HAS_CMI = False
    
    try:
        from tigramite.independence_tests.gpdc import GPDC
        HAS_GPDC = True
    except ImportError:
        HAS_GPDC = False
        
except ImportError:
    HAS_TIGRAMITE = False
    HAS_CMI = False
    HAS_GPDC = False
    logger.warning("‚ö†Ô∏è Tigramite not installed. Install with: pip install tigramite")


class IndependenceTest:
    """Enumeration of available independence tests."""
    PARCORR = "parcorr"      # Partial correlation (linear)
    CMI = "cmi"              # Conditional mutual information (nonlinear)
    GPDC = "gpdc"            # Gaussian process distance correlation


@dataclass
class CausalLink:
    """A discovered causal link."""
    source: str
    target: str
    lag: int  # Time lag in data points
    strength: float  # Raw correlation/MI value
    p_value: float
    score: float  # Confidence score (0-1)
    test_used: str
    validated: bool = False
    physics_plausible: bool = True
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __repr__(self):
        return f"CausalLink({self.source} ‚Üí[{self.lag}] {self.target}, score={self.score:.3f})"
    
    def to_dict(self) -> Dict:
        return {
            "source": self.source,
            "target": self.target,
            "lag": self.lag,
            "strength": self.strength,
            "p_value": self.p_value,
            "score": self.score,
            "test_used": self.test_used,
            "validated": self.validated,
            "physics_plausible": self.physics_plausible,
            "metadata": self.metadata,
        }


@dataclass
class PCMCIResult:
    """Result of PCMCI causal discovery."""
    significant_links: List[CausalLink]
    all_links: List[CausalLink]
    var_names: List[str]
    val_matrix: np.ndarray
    p_matrix: np.ndarray
    conf_matrix: Optional[np.ndarray]
    method: str
    max_lag: int
    alpha: float
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def get_parents(self, var: str, min_score: float = 0.5) -> List[CausalLink]:
        """Get all causal parents of a variable."""
        return [
            link for link in self.significant_links
            if link.target == var and link.score >= min_score
        ]
    
    def get_children(self, var: str, min_score: float = 0.5) -> List[CausalLink]:
        """Get all causal children of a variable."""
        return [
            link for link in self.significant_links
            if link.source == var and link.score >= min_score
        ]
    
    def to_dict(self) -> Dict:
        return {
            "significant_links": [l.to_dict() for l in self.significant_links],
            "var_names": self.var_names,
            "method": self.method,
            "max_lag": self.max_lag,
            "alpha": self.alpha,
            "timestamp": self.timestamp,
            "n_significant": len(self.significant_links),
            "metadata": self.metadata,
        }
    
    def to_graph_dict(self) -> Dict:
        """Convert to format suitable for graph visualization."""
        nodes = [{"id": v, "label": v} for v in self.var_names]
        edges = [
            {
                "source": l.source,
                "target": l.target,
                "weight": l.score,
                "lag": l.lag,
            }
            for l in self.significant_links
        ]
        return {"nodes": nodes, "edges": edges}


class PCMCIEngine:
    """
    PCMCI-based causal discovery engine.
    
    Uses tigramite for rigorous time-lagged causal discovery.
    """
    
    def __init__(
        self,
        max_lag: int = 30,
        alpha: float = 0.05,
        ci_test: str = IndependenceTest.PARCORR,
        min_effect_size: float = 0.1,
        pc_alpha: Optional[float] = None,
        verbose: bool = False,
    ):
        """
        Initialize PCMCI engine.
        
        Args:
            max_lag: Maximum time lag to test (in data points)
            alpha: Significance level for links
            ci_test: Conditional independence test to use
            min_effect_size: Minimum effect size to consider significant
            pc_alpha: Alpha for PC stable step (None = no PC step)
            verbose: Print debug info
        """
        self.max_lag = max_lag
        self.alpha = alpha
        self.ci_test = ci_test
        self.min_effect_size = min_effect_size
        self.pc_alpha = pc_alpha
        self.verbose = verbose
        
        if not HAS_TIGRAMITE:
            raise ImportError(
                "Tigramite is required for PCMCI. "
                "Install with: pip install tigramite"
            )
    
    def _create_independence_test(self):
        """Create the appropriate independence test object."""
        if self.ci_test == IndependenceTest.PARCORR:
            return ParCorr(significance="analytic")
        
        elif self.ci_test == IndependenceTest.CMI and HAS_CMI:
            return CMIknn(significance="shuffle_test", knn=10)
        
        elif self.ci_test == IndependenceTest.GPDC and HAS_GPDC:
            return GPDC(significance="analytic")
        
        else:
            logger.warning(f"Test {self.ci_test} not available, using ParCorr")
            return ParCorr(significance="analytic")
    
    def discover(
        self,
        df: pd.DataFrame,
        target: Optional[str] = None,
        selected_vars: Optional[List[str]] = None,
        lag_override: Optional[Dict[str, int]] = None,
    ) -> PCMCIResult:
        """
        Run PCMCI causal discovery.
        
        Args:
            df: DataFrame with time series (rows=time, cols=variables)
            target: If specified, only find causes of this variable
            selected_vars: If specified, only analyze these variables
            lag_override: Dict of variable -> max_lag for specific vars
            
        Returns:
            PCMCIResult with discovered causal links
        """
        # Select variables
        if selected_vars:
            df = df[selected_vars]
        
        var_names = list(df.columns)
        n_vars = len(var_names)
        
        # Handle missing data
        df = df.ffill().bfill()
        
        # Check for sufficient data
        min_samples = self.max_lag * 3 + 10
        if len(df) < min_samples:
            logger.warning(
                f"Insufficient data ({len(df)} samples). "
                f"Reducing max_lag from {self.max_lag} to {len(df) // 4}"
            )
            self.max_lag = max(1, len(df) // 4)
        
        # Standardize data
        data = df.values
        data = (data - data.mean(axis=0)) / (data.std(axis=0) + 1e-10)
        
        # Create Tigramite dataframe
        dataframe = pp.DataFrame(
            data,
            var_names=var_names,
        )
        
        # Create independence test
        cond_ind_test = self._create_independence_test()
        
        # Initialize PCMCI
        pcmci = PCMCI(
            dataframe=dataframe,
            cond_ind_test=cond_ind_test,
            verbosity=1 if self.verbose else 0,
        )
        
        # Run appropriate PCMCI variant
        if self.pc_alpha is not None:
            # Run full PCMCI (with PC condition selection)
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                results = pcmci.run_pcmci(
                    tau_max=self.max_lag,
                    pc_alpha=self.pc_alpha,
                    alpha_level=self.alpha,
                )
        else:
            # Run PCMCI+ (no PC step, tests all links)
            try:
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    results = pcmci.run_pcmciplus(
                        tau_min=0,
                        tau_max=self.max_lag,
                    )
            except AttributeError:
                # Fallback for older tigramite
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    results = pcmci.run_pcmci(
                        tau_max=self.max_lag,
                        alpha_level=self.alpha,
                    )
        
        # Extract matrices
        val_matrix = results.get("val_matrix")
        p_matrix = results.get("p_matrix")
        conf_matrix = results.get("conf_matrix")  # May be None
        
        # Build causal links
        all_links = []
        significant_links = []
        
        for i in range(n_vars):
            for j in range(n_vars):
                for lag in range(self.max_lag + 1):
                    # Skip contemporaneous self-loops
                    if i == j and lag == 0:
                        continue
                    
                    # Get values
                    strength = float(val_matrix[i, j, lag])
                    p_value = float(p_matrix[i, j, lag])
                    
                    # Skip NaN or very weak
                    if np.isnan(strength) or np.isnan(p_value):
                        continue
                    
                    # Calculate score
                    score = self._calculate_score(strength, p_value)
                    
                    link = CausalLink(
                        source=var_names[i],
                        target=var_names[j],
                        lag=lag,
                        strength=strength,
                        p_value=p_value,
                        score=score,
                        test_used=self.ci_test,
                        metadata={
                            "source_idx": i,
                            "target_idx": j,
                        }
                    )
                    all_links.append(link)
                    
                    # Check significance
                    if p_value < self.alpha and abs(strength) >= self.min_effect_size:
                        # Filter by target if specified
                        if target is None or link.target == target:
                            significant_links.append(link)
        
        # Sort by score
        significant_links.sort(key=lambda x: x.score, reverse=True)
        
        return PCMCIResult(
            significant_links=significant_links,
            all_links=all_links,
            var_names=var_names,
            val_matrix=val_matrix,
            p_matrix=p_matrix,
            conf_matrix=conf_matrix,
            method="pcmci" if self.pc_alpha else "pcmci+",
            max_lag=self.max_lag,
            alpha=self.alpha,
            metadata={
                "n_samples": len(df),
                "ci_test": self.ci_test,
                "min_effect_size": self.min_effect_size,
            }
        )
    
    def _calculate_score(self, strength: float, p_value: float) -> float:
        """
        Calculate confidence score from strength and p-value.
        
        Score combines:
        - Effect size (strength): How strong is the relationship
        - Statistical significance (p-value): How confident are we
        
        Returns value in [0, 1].
        """
        # Effect size component (0-1)
        effect_score = min(1.0, abs(strength))
        
        # Significance component (0-1)
        # Transform p-value to score: 0.001 ‚Üí ~1.0, 0.05 ‚Üí ~0.5, 0.5 ‚Üí ~0
        if p_value <= 0:
            sig_score = 1.0
        else:
            sig_score = min(1.0, -np.log10(p_value) / 3.0)
        
        # Combined score
        # Weight effect size slightly more as we already filter by alpha
        score = 0.4 * effect_score + 0.6 * sig_score
        
        return float(np.clip(score, 0, 1))
    
    def validate_links(
        self,
        result: PCMCIResult,
        df: pd.DataFrame,
        n_splits: int = 5,
    ) -> PCMCIResult:
        """
        Cross-validate discovered links.
        
        Runs PCMCI on subsets of data to validate stability of links.
        """
        n_samples = len(df)
        split_size = n_samples // n_splits
        
        link_counts: Dict[Tuple[str, str, int], int] = {}
        
        for i in range(n_splits):
            # Leave one split out
            mask = np.ones(n_samples, dtype=bool)
            start = i * split_size
            end = min(start + split_size, n_samples)
            mask[start:end] = False
            
            df_subset = df.iloc[mask]
            
            # Run PCMCI on subset
            try:
                sub_result = self.discover(df_subset)
                
                for link in sub_result.significant_links:
                    key = (link.source, link.target, link.lag)
                    link_counts[key] = link_counts.get(key, 0) + 1
            except Exception as e:
                logger.warning(f"Validation split {i} failed: {e}")
        
        # Mark validated links
        for link in result.significant_links:
            key = (link.source, link.target, link.lag)
            count = link_counts.get(key, 0)
            link.validated = count >= n_splits * 0.6  # Found in 60%+ of splits
            link.metadata["validation_count"] = count
            link.metadata["validation_ratio"] = count / n_splits
        
        return result
    
    def add_physics_constraints(
        self,
        result: PCMCIResult,
        constraints: Dict[str, List[str]] = None,
    ) -> PCMCIResult:
        """
        Mark links as physics-plausible based on domain knowledge.
        
        Args:
            result: PCMCI result to annotate
            constraints: Dict of target -> list of plausible causes
            
        Default climate physics constraints:
        - SST can be caused by wind, solar radiation, currents
        - Sea level can be caused by wind, pressure, temperature
        - NAO/ENSO can cause many things but are not caused by local vars
        """
        # Default oceanographic constraints
        if constraints is None:
            constraints = {
                "sla": ["wind", "pressure", "sst", "nao", "enso", "current"],
                "sst": ["wind", "solar", "current", "mixing", "adt"],
                "flood": ["precipitation", "sla", "wind", "nao", "pressure"],
                "wave_height": ["wind", "sst", "pressure"],
            }
            
            # Climate indices shouldn't be caused by local variables
            climate_indices = ["nao", "enso", "amo", "pdo", "ao"]
        
        for link in result.significant_links:
            target_lower = link.target.lower()
            source_lower = link.source.lower()
            
            # Check if source is in allowed causes
            is_plausible = True
            
            for target_key, allowed_causes in constraints.items():
                if target_key in target_lower:
                    # Check if any allowed cause matches
                    matches = any(cause in source_lower for cause in allowed_causes)
                    if not matches:
                        is_plausible = False
                    break
            
            # Climate indices shouldn't have local causes
            if any(idx in target_lower for idx in ["nao", "enso", "amo", "pdo"]):
                if not any(idx in source_lower for idx in ["nao", "enso", "amo", "pdo"]):
                    is_plausible = False
            
            link.physics_plausible = is_plausible
        
        return result


# Async wrapper
async def discover_causal_links(
    df: pd.DataFrame,
    max_lag: int = 30,
    alpha: float = 0.05,
    target: Optional[str] = None,
    validate: bool = True,
) -> PCMCIResult:
    """
    Async wrapper for PCMCI causal discovery.
    
    Args:
        df: Time series DataFrame
        max_lag: Maximum lag to test
        alpha: Significance level
        target: Target variable (optional)
        validate: Cross-validate results
        
    Returns:
        PCMCIResult with discovered links
    """
    engine = PCMCIEngine(max_lag=max_lag, alpha=alpha)
    result = engine.discover(df, target=target)
    
    if validate:
        result = engine.validate_links(result, df)
    
    result = engine.add_physics_constraints(result)
    
    return result


# CLI test
if __name__ == "__main__":
    # Test with synthetic data
    print("=== PCMCI Engine Test ===\n")
    
    if not HAS_TIGRAMITE:
        print("‚ùå Tigramite not installed. Install with:")
        print("   pip install tigramite")
        exit(1)
    
    # Generate synthetic causal data
    np.random.seed(42)
    n = 500
    
    # X causes Y with lag 5
    x = np.random.randn(n)
    noise = np.random.randn(n) * 0.3
    y = np.zeros(n)
    for t in range(5, n):
        y[t] = 0.8 * x[t - 5] + noise[t]
    
    # Z is independent
    z = np.random.randn(n)
    
    df = pd.DataFrame({
        "X": x,
        "Y": y,
        "Z": z,
    })
    
    print(f"Data shape: {df.shape}")
    print(f"Variables: {list(df.columns)}")
    
    # Run PCMCI
    engine = PCMCIEngine(max_lag=10, alpha=0.05)
    result = engine.discover(df)
    
    print(f"\n‚úÖ Found {len(result.significant_links)} significant links:\n")
    
    for link in result.significant_links:
        print(f"  {link.source} ‚Üí[lag={link.lag}] {link.target}")
        print(f"    strength={link.strength:.3f}, p={link.p_value:.4f}, score={link.score:.3f}")
    
    # Validate
    print("\nüîÑ Cross-validating...")
    result = engine.validate_links(result, df, n_splits=3)
    
    for link in result.significant_links:
        status = "‚úì" if link.validated else "?"
        print(f"  {status} {link.source} ‚Üí {link.target}: validated={link.validated}")
